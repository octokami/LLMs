{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0422c89",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "\"Small\" subsets Data from Grocery and Gourmet Food\n",
    "https://nijianmo.github.io/amazon/index.html (May 1996 - Oct 2018)\n",
    "\n",
    "Justifying recommendations using distantly-labeled reviews and fined-grained aspects\n",
    "Jianmo Ni, Jiacheng Li, Julian McAuley\n",
    "Empirical Methods in Natural Language Processing (EMNLP), 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a0fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f90c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>01 11, 2008</td>\n",
       "      <td>A1YWGQTI76DQCP</td>\n",
       "      <td>B000BQ7GW8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Book Lover</td>\n",
       "      <td>I'm sure this item performs well in the right ...</td>\n",
       "      <td>Deceptive advertising</td>\n",
       "      <td>1200009600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>01 7, 2008</td>\n",
       "      <td>A3FM34ZYGZJHDF</td>\n",
       "      <td>B000BQ7GW8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stan J. Diamanti</td>\n",
       "      <td>Very satisified with delevery and quality of p...</td>\n",
       "      <td>Written review</td>\n",
       "      <td>1199664000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>05 13, 2018</td>\n",
       "      <td>A3JWJLNZ8R12N3</td>\n",
       "      <td>B000BQ7GW8</td>\n",
       "      <td>{'Size:': ' 32 GB', 'Package Type:': ' Frustra...</td>\n",
       "      <td>Tony F</td>\n",
       "      <td>works fine</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1526169600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>05 11, 2018</td>\n",
       "      <td>A1BF6YF4HUYGHD</td>\n",
       "      <td>B000BQ7GW8</td>\n",
       "      <td>{'Size:': ' 32 GB', 'Package Type:': ' Frustra...</td>\n",
       "      <td>Kevin Brill</td>\n",
       "      <td>A1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1525996800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>05 11, 2018</td>\n",
       "      <td>A22F65OPY10FAG</td>\n",
       "      <td>B000BQ7GW8</td>\n",
       "      <td>{'Size:': ' 32 GB', 'Package Type:': ' Frustra...</td>\n",
       "      <td>LDSaint</td>\n",
       "      <td>All of the scandisk products I have purchased ...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1525996800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0      3.0    3      True  01 11, 2008  A1YWGQTI76DQCP  B000BQ7GW8   \n",
       "1      5.0  NaN     False   01 7, 2008  A3FM34ZYGZJHDF  B000BQ7GW8   \n",
       "2      5.0  NaN      True  05 13, 2018  A3JWJLNZ8R12N3  B000BQ7GW8   \n",
       "3      5.0  NaN      True  05 11, 2018  A1BF6YF4HUYGHD  B000BQ7GW8   \n",
       "4      5.0  NaN      True  05 11, 2018  A22F65OPY10FAG  B000BQ7GW8   \n",
       "\n",
       "                                               style      reviewerName  \\\n",
       "0                                                NaN        Book Lover   \n",
       "1                                                NaN  Stan J. Diamanti   \n",
       "2  {'Size:': ' 32 GB', 'Package Type:': ' Frustra...            Tony F   \n",
       "3  {'Size:': ' 32 GB', 'Package Type:': ' Frustra...       Kevin Brill   \n",
       "4  {'Size:': ' 32 GB', 'Package Type:': ' Frustra...           LDSaint   \n",
       "\n",
       "                                          reviewText                summary  \\\n",
       "0  I'm sure this item performs well in the right ...  Deceptive advertising   \n",
       "1  Very satisified with delevery and quality of p...         Written review   \n",
       "2                                         works fine             Five Stars   \n",
       "3                                                 A1             Five Stars   \n",
       "4  All of the scandisk products I have purchased ...             Five Stars   \n",
       "\n",
       "   unixReviewTime image  \n",
       "0      1200009600   NaN  \n",
       "1      1199664000   NaN  \n",
       "2      1526169600   NaN  \n",
       "3      1525996800   NaN  \n",
       "4      1525996800   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output folder\n",
    "in_dir = 'data'\n",
    "out_dir = 'model_output'\n",
    "\n",
    "# Create the output directory\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "product_df = pd.read_pickle('{}\\product_df.pkl'.format(in_dir))\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0f5b0c-2be5-4ef1-bf6d-aab5076df5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tech1</th>\n",
       "      <th>description</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>tech2</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>similar_item</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>imageURL</th>\n",
       "      <th>imageURLHighRes</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Compute...</td>\n",
       "      <td></td>\n",
       "      <td>[SanDisk Standard SD cards give you plenty of ...</td>\n",
       "      <td></td>\n",
       "      <td>SanDisk 2GB Class 4 SD Flash Memory Card- SDSD...</td>\n",
       "      <td>[B0009RGLSE, B000WHCB94, B000FGNM6I, B00FYX1AB...</td>\n",
       "      <td></td>\n",
       "      <td>SanDisk</td>\n",
       "      <td>[Cards include security feature for protection...</td>\n",
       "      <td>[&gt;#196 in Computers &amp; Accessories &gt; Computer A...</td>\n",
       "      <td>[B0009RGLSE, B000YH5FOK, B000FGNM6I, B0143RTB1...</td>\n",
       "      <td>All Electronics</td>\n",
       "      <td>class=\"a-bordered a-horizontal-stripes  a-spa...</td>\n",
       "      <td>October 2, 2001</td>\n",
       "      <td>$4.99</td>\n",
       "      <td>B000BQ7GW8</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Compute...</td>\n",
       "      <td>class=\"a-keyvalue prodDetTable\" role=\"present...</td>\n",
       "      <td>[This USB 2.0 to IDE/SATA Adapter Cable connec...</td>\n",
       "      <td></td>\n",
       "      <td>StarTech USB 2.0 to SATA IDE Adapter (USB2SATA...</td>\n",
       "      <td>[B00348K5XW, B0016RTMQE, B078DPCY3T, B07GFJKDD...</td>\n",
       "      <td></td>\n",
       "      <td>StarTech</td>\n",
       "      <td>[Supports both 2.5in and 3.5in SATA/IDE hard d...</td>\n",
       "      <td>[&gt;#68 in Computers &amp; Accessories &gt; Computer Ac...</td>\n",
       "      <td>[B00LD2FKOK, B00DQJME7Y, B008YLNTPA, B0758RP5V...</td>\n",
       "      <td>All Electronics</td>\n",
       "      <td>class=\"a-bordered a-horizontal-stripes  a-spa...</td>\n",
       "      <td>July 7, 2004</td>\n",
       "      <td>$18.80</td>\n",
       "      <td>B000VS4HDM</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Electronics, Accessories &amp; Supplies, Power St...</td>\n",
       "      <td></td>\n",
       "      <td>[Mini Surge Protector with USB Charger, Whethe...</td>\n",
       "      <td></td>\n",
       "      <td>Belkin BZ103050-TVL Mini Surge Protector with...</td>\n",
       "      <td>[B017JZF422, B018RI6MFI, B015DRJDNO, B071VFWX3...</td>\n",
       "      <td></td>\n",
       "      <td>Belkin</td>\n",
       "      <td>[Compact and Convenient: Charge 3 AC powered d...</td>\n",
       "      <td>[&gt;#21 in Electronics &gt; Accessories &amp; Supplies ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>All Electronics</td>\n",
       "      <td>class=\"a-bordered a-horizontal-stripes  a-spa...</td>\n",
       "      <td>October 2, 2001</td>\n",
       "      <td>$2.00</td>\n",
       "      <td>B0015DYMVO</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Electronics, Accessories &amp; Supplies, Audio &amp; ...</td>\n",
       "      <td></td>\n",
       "      <td>[&lt;b&gt;Mediabridge ULTRA Series HDMI Cable&lt;/b&gt;&lt;br...</td>\n",
       "      <td></td>\n",
       "      <td>Mediabridge HDMI Cable (6 Feet) Supports 4K@60...</td>\n",
       "      <td>[B004LSNF04, B00VPFQ1GG, B003FW0WIK, B078HXF9H...</td>\n",
       "      <td></td>\n",
       "      <td>Mediabridge</td>\n",
       "      <td>[INDIVIDUALLY HAND-TESTED: Every cable is chec...</td>\n",
       "      <td>[&gt;#157 in Electronics &gt; Accessories &amp; Supplies...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "      <td>class=\"a-bordered a-horizontal-stripes  a-spa...</td>\n",
       "      <td>May 23, 2008</td>\n",
       "      <td>$9.99</td>\n",
       "      <td>B0019EHU8G</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Electronics, Accessories &amp; Supplies, Audio &amp; ...</td>\n",
       "      <td></td>\n",
       "      <td>[&lt;b&gt;Mediabridge ULTRA Series HDMI Cable&lt;/b&gt;&lt;br...</td>\n",
       "      <td></td>\n",
       "      <td>Mediabridge HDMI Cable (10 Feet) Supports 4K@6...</td>\n",
       "      <td>[B004LTE5JI, B004LT2C5W, B005T3LKKM, B004LSNF0...</td>\n",
       "      <td></td>\n",
       "      <td>Mediabridge</td>\n",
       "      <td>[INDIVIDUALLY HAND-TESTED: Every cable is chec...</td>\n",
       "      <td>[&gt;#183 in Electronics &gt; Accessories &amp; Supplies...</td>\n",
       "      <td>[B003XM1WE0, B004LTE5JI, B009K4J8RS, B005T3LKK...</td>\n",
       "      <td>All Electronics</td>\n",
       "      <td>class=\"a-bordered a-horizontal-stripes  a-spa...</td>\n",
       "      <td>May 23, 2008</td>\n",
       "      <td>$9.99</td>\n",
       "      <td>B0019HL8Q8</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category  \\\n",
       "0  [Electronics, Computers & Accessories, Compute...   \n",
       "1  [Electronics, Computers & Accessories, Compute...   \n",
       "2  [Electronics, Accessories & Supplies, Power St...   \n",
       "3  [Electronics, Accessories & Supplies, Audio & ...   \n",
       "4  [Electronics, Accessories & Supplies, Audio & ...   \n",
       "\n",
       "                                               tech1  \\\n",
       "0                                                      \n",
       "1   class=\"a-keyvalue prodDetTable\" role=\"present...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                         description fit  \\\n",
       "0  [SanDisk Standard SD cards give you plenty of ...       \n",
       "1  [This USB 2.0 to IDE/SATA Adapter Cable connec...       \n",
       "2  [Mini Surge Protector with USB Charger, Whethe...       \n",
       "3  [<b>Mediabridge ULTRA Series HDMI Cable</b><br...       \n",
       "4  [<b>Mediabridge ULTRA Series HDMI Cable</b><br...       \n",
       "\n",
       "                                               title  \\\n",
       "0  SanDisk 2GB Class 4 SD Flash Memory Card- SDSD...   \n",
       "1  StarTech USB 2.0 to SATA IDE Adapter (USB2SATA...   \n",
       "2   Belkin BZ103050-TVL Mini Surge Protector with...   \n",
       "3  Mediabridge HDMI Cable (6 Feet) Supports 4K@60...   \n",
       "4  Mediabridge HDMI Cable (10 Feet) Supports 4K@6...   \n",
       "\n",
       "                                            also_buy tech2        brand  \\\n",
       "0  [B0009RGLSE, B000WHCB94, B000FGNM6I, B00FYX1AB...            SanDisk   \n",
       "1  [B00348K5XW, B0016RTMQE, B078DPCY3T, B07GFJKDD...           StarTech   \n",
       "2  [B017JZF422, B018RI6MFI, B015DRJDNO, B071VFWX3...             Belkin   \n",
       "3  [B004LSNF04, B00VPFQ1GG, B003FW0WIK, B078HXF9H...        Mediabridge   \n",
       "4  [B004LTE5JI, B004LT2C5W, B005T3LKKM, B004LSNF0...        Mediabridge   \n",
       "\n",
       "                                             feature  \\\n",
       "0  [Cards include security feature for protection...   \n",
       "1  [Supports both 2.5in and 3.5in SATA/IDE hard d...   \n",
       "2  [Compact and Convenient: Charge 3 AC powered d...   \n",
       "3  [INDIVIDUALLY HAND-TESTED: Every cable is chec...   \n",
       "4  [INDIVIDUALLY HAND-TESTED: Every cable is chec...   \n",
       "\n",
       "                                                rank  \\\n",
       "0  [>#196 in Computers & Accessories > Computer A...   \n",
       "1  [>#68 in Computers & Accessories > Computer Ac...   \n",
       "2  [>#21 in Electronics > Accessories & Supplies ...   \n",
       "3  [>#157 in Electronics > Accessories & Supplies...   \n",
       "4  [>#183 in Electronics > Accessories & Supplies...   \n",
       "\n",
       "                                           also_view              main_cat  \\\n",
       "0  [B0009RGLSE, B000YH5FOK, B000FGNM6I, B0143RTB1...       All Electronics   \n",
       "1  [B00LD2FKOK, B00DQJME7Y, B008YLNTPA, B0758RP5V...       All Electronics   \n",
       "2                                                 []       All Electronics   \n",
       "3                                                 []  Home Audio & Theater   \n",
       "4  [B003XM1WE0, B004LTE5JI, B009K4J8RS, B005T3LKK...       All Electronics   \n",
       "\n",
       "                                        similar_item             date   price  \\\n",
       "0   class=\"a-bordered a-horizontal-stripes  a-spa...  October 2, 2001   $4.99   \n",
       "1   class=\"a-bordered a-horizontal-stripes  a-spa...     July 7, 2004  $18.80   \n",
       "2   class=\"a-bordered a-horizontal-stripes  a-spa...  October 2, 2001   $2.00   \n",
       "3   class=\"a-bordered a-horizontal-stripes  a-spa...     May 23, 2008   $9.99   \n",
       "4   class=\"a-bordered a-horizontal-stripes  a-spa...     May 23, 2008   $9.99   \n",
       "\n",
       "         asin                                           imageURL  \\\n",
       "0  B000BQ7GW8  [https://images-na.ssl-images-amazon.com/image...   \n",
       "1  B000VS4HDM  [https://images-na.ssl-images-amazon.com/image...   \n",
       "2  B0015DYMVO  [https://images-na.ssl-images-amazon.com/image...   \n",
       "3  B0019EHU8G  [https://images-na.ssl-images-amazon.com/image...   \n",
       "4  B0019HL8Q8  [https://images-na.ssl-images-amazon.com/image...   \n",
       "\n",
       "                                     imageURLHighRes details  \n",
       "0  [https://images-na.ssl-images-amazon.com/image...      {}  \n",
       "1  [https://images-na.ssl-images-amazon.com/image...      {}  \n",
       "2  [https://images-na.ssl-images-amazon.com/image...      {}  \n",
       "3  [https://images-na.ssl-images-amazon.com/image...      {}  \n",
       "4  [https://images-na.ssl-images-amazon.com/image...      {}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_pickle('{}\\meta_product_df.pkl'.format(in_dir))\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d2080-6593-4988-ad39-2a7545c2bee4",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e0dd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Very satisified with delevery and quality of product.  SanDisk 4 GB SD Memory Card (SDSDB-4096-A11)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = product_df['reviewText'].iloc[1]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57bd94f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WAY TOO EXPENSIVE!!!!!!!!!!!!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df['reviewText'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433d625f-12e1-4c41-b836-fcbd9173e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delevery\n",
      "quality\n",
      "product\n",
      "SDSDB-4096-A11\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "doc = nlp(review)\n",
    "#doc.ents #no entities\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3266c",
   "metadata": {},
   "source": [
    "## Centroid-based Text Summarization through Compositionality of Word Embeddings\n",
    "* Paper: http://dx.doi.org/10.18653/v1/W17-1003\n",
    "* Code: https://github.com/gaetangate/text-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a8f03f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub\n",
      "          which has been launched to empower the next generation of students with AI-ready skills.\n",
      "1 Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100\n",
      "          institutions with AI infrastructure, course content and curriculum, developer support,\n",
      "          development tools and give students access to cloud and AI services.\n",
      "2 As part of the program, the Redmond giant which wants to expand its reach and is\n",
      "          planning to build a strong developer ecosystem in India with the program will set up the\n",
      "          core AI infrastructure and IoT Hub for the selected campuses.\n",
      "3 The company will provide AI development tools and Azure AI services such as\n",
      "          Microsoft Cognitive Services, Bot Services and Azure Machine Learning.\n",
      "4 According to Manish Prakash, Country General Manager-PS, Health and Education,\n",
      "          Microsoft India, said, \"With AI being the defining technology of our time,\n",
      "          it is transforming lives and industry and the jobs of tomorrow will\n",
      "          require a different skillset.\n",
      "5 This will require more collaborations and\n",
      "          training and working with AI.\n",
      "6 That’s why it has become more critical than ever for\n",
      "          educational institutions to integrate new cloud and AI technologies.\n",
      "7 The program is an attempt to ramp up the institutional set-up and build\n",
      "          capabilities among the educators to educate the workforce of tomorrow.\"\n",
      "8 The program aims to build up the cognitive skills and in-depth understanding of\n",
      "          developing intelligent cloud connected solutions for applications across industry.\n",
      "9 Earlier in April this year, the company announced Microsoft Professional\n",
      "          Program In AI as a learning track open to the public.\n",
      "10 The program was developed to provide job ready skills to programmers who wanted to hone their\n",
      "          skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well.\n",
      "11 This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.\n",
      "0 attempt build ai-ready workforce microsoft announced intelligent cloud hub launched empower next generation students ai-ready skills\n",
      "1 envisioned three-year collaborative program intelligent cloud hub support around 100 institutions ai infrastructure course content curriculum developer support development tools give students access cloud ai services\n",
      "2 part program redmond giant wants expand reach planning build strong developer ecosystem india program set core ai infrastructure iot hub selected campuses\n",
      "3 company provide ai development tools azure ai services microsoft cognitive services bot services azure machine learning\n",
      "4 according manish prakash country general manager-ps health education microsoft india said `` ai defining technology time transforming lives industry jobs tomorrow require different skillset\n",
      "5 require collaborations training working ai\n",
      "6 ’ become critical ever educational institutions integrate new cloud ai technologies\n",
      "7 program attempt ramp institutional set-up build capabilities among educators educate workforce tomorrow ''\n",
      "8 program aims build cognitive skills in-depth understanding developing intelligent cloud connected solutions applications across industry\n",
      "9 earlier april year company announced microsoft professional program ai learning track open public\n",
      "10 program developed provide job ready skills programmers wanted hone skills ai data science series online courses featured hands-on labs expert instructors well\n",
      "11 program also included developer-focused ai school provided bunch assets help build ai skills\n",
      "31 ['ai', 'announced', 'attempt', 'azure', 'build', 'cloud', 'cognitive', 'company', 'developer', 'development', 'hub', 'india', 'industry', 'infrastructure', 'institutions', 'intelligent', 'learning', 'microsoft', 'program', 'provide', 'ready', 'require', 'services', 'set', 'skills', 'students', 'support', 'tomorrow', 'tools', 'workforce', 'year']\n",
      "1 Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100\n",
      "          institutions with AI infrastructure, course content and curriculum, developer support,\n",
      "          development tools and give students access to cloud and AI services. 0.8326923847198486\n",
      "3 The company will provide AI development tools and Azure AI services such as\n",
      "          Microsoft Cognitive Services, Bot Services and Azure Machine Learning. 0.7905132472515106\n",
      "0 In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub\n",
      "          which has been launched to empower the next generation of students with AI-ready skills. 0.7390074729919434\n",
      "9 Earlier in April this year, the company announced Microsoft Professional\n",
      "          Program In AI as a learning track open to the public. 0.7175984531641006\n",
      "2 As part of the program, the Redmond giant which wants to expand its reach and is\n",
      "          planning to build a strong developer ecosystem in India with the program will set up the\n",
      "          core AI infrastructure and IoT Hub for the selected campuses. 0.7138122916221619\n",
      "8 The program aims to build up the cognitive skills and in-depth understanding of\n",
      "          developing intelligent cloud connected solutions for applications across industry. 0.7050146609544754\n",
      "11 This program also included developer-focused AI school that provided a bunch of assets to help build AI skills. 0.7009086161851883\n",
      "10 The program was developed to provide job ready skills to programmers who wanted to hone their\n",
      "          skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well. 0.6859303563833237\n",
      "4 According to Manish Prakash, Country General Manager-PS, Health and Education,\n",
      "          Microsoft India, said, \"With AI being the defining technology of our time,\n",
      "          it is transforming lives and industry and the jobs of tomorrow will\n",
      "          require a different skillset. 0.6725911796092987\n",
      "6 That’s why it has become more critical than ever for\n",
      "          educational institutions to integrate new cloud and AI technologies. 0.622642032802105\n",
      "5 This will require more collaborations and\n",
      "          training and working with AI. 0.6064465790987015\n",
      "7 The program is an attempt to ramp up the institutional set-up and build\n",
      "          capabilities among the educators to educate the workforce of tomorrow.\" 0.5707117393612862\n",
      "In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub\n",
      "          which has been launched to empower the next generation of students with AI-ready skills.\n",
      "Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100\n",
      "          institutions with AI infrastructure, course content and curriculum, developer support,\n",
      "          development tools and give students access to cloud and AI services.\n",
      "The company will provide AI development tools and Azure AI services such as\n",
      "          Microsoft Cognitive Services, Bot Services and Azure Machine Learning.\n",
      "Earlier in April this year, the company announced Microsoft Professional\n",
      "          Program In AI as a learning track open to the public.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\camil\\anaconda3\\envs\\pytorch_venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub\\n          which has been launched to empower the next generation of students with AI-ready skills.\\nEnvisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100\\n          institutions with AI infrastructure, course content and curriculum, developer support,\\n          development tools and give students access to cloud and AI services.\\nThe company will provide AI development tools and Azure AI services such as\\n          Microsoft Cognitive Services, Bot Services and Azure Machine Learning.\\nEarlier in April this year, the company announced Microsoft Professional\\n          Program In AI as a learning track open to the public.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize as nlkt_sent_tokenize\n",
    "from nltk.tokenize import word_tokenize as nlkt_word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "#Calculates cosine similarity\n",
    "def similarity(v1, v2):\n",
    "    score = 0.0\n",
    "    if np.count_nonzero(v1) != 0 and np.count_nonzero(v2) != 0:\n",
    "        score = ((1 - cosine(v1, v2)) + 1) / 2\n",
    "    return score\n",
    "\n",
    "def sent_tokenize(text):\n",
    "    sents = nlkt_sent_tokenize(text)\n",
    "    sents_filtered = []\n",
    "    for s in sents:\n",
    "        sents_filtered.append(s)\n",
    "    return sents_filtered\n",
    "\n",
    "def cleanup_sentences(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences_cleaned = []\n",
    "    for sent in sentences:\n",
    "        words = nlkt_word_tokenize(sent)\n",
    "        words = [w for w in words if w not in string.punctuation]\n",
    "        words = [w for w in words if not w.lower() in stop_words]\n",
    "        words = [w.lower() for w in words]\n",
    "        sentences_cleaned.append(\" \".join(words))\n",
    "    return sentences_cleaned\n",
    "\n",
    "def get_tf_idf(sentences):\n",
    "    vectorizer = CountVectorizer()\n",
    "    sent_word_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    transformer = TfidfTransformer(norm=None, sublinear_tf=False, smooth_idf=False)\n",
    "    tfidf = transformer.fit_transform(sent_word_matrix)\n",
    "    tfidf = tfidf.toarray()\n",
    "\n",
    "    centroid_vector = tfidf.sum(0)\n",
    "    centroid_vector = np.divide(centroid_vector, centroid_vector.max())\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    relevant_vector_indices = np.where(centroid_vector > 0.3)[0]\n",
    "\n",
    "    word_list = list(np.array(feature_names)[relevant_vector_indices])\n",
    "    return word_list\n",
    "\n",
    "#Populate word vector with all embeddings.\n",
    "#This word vector is a look up table that is used\n",
    "#for getting the centroid and sentences embedding representation.\n",
    "def word_vectors_cache(sentences, embedding_model):\n",
    "    word_vectors = dict()\n",
    "    for sent in sentences:\n",
    "        words = nlkt_word_tokenize(sent)\n",
    "        for w in words:\n",
    "            word_vectors.update({w: embedding_model.wv[w]})\n",
    "    return word_vectors\n",
    "\n",
    "# Sentence embedding representation with sum of word vectors\n",
    "def build_embedding_representation(words, word_vectors, embedding_model):\n",
    "    embedding_representation = np.zeros(embedding_model.vector_size, dtype=\"float32\")\n",
    "    word_vectors_keys = set(word_vectors.keys())\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_vectors_keys:\n",
    "            embedding_representation = embedding_representation + word_vectors[w]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "       embedding_representation = np.divide(embedding_representation, count)\n",
    "    return embedding_representation\n",
    "\n",
    "def summarize(text, emdedding_model):\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    clean_sentences = cleanup_sentences(text)\n",
    "    for i, s in enumerate(raw_sentences):\n",
    "        print(i, s)\n",
    "    for i, s in enumerate(clean_sentences):\n",
    "        print(i, s)\n",
    "    centroid_words = get_tf_idf(clean_sentences)\n",
    "    print(len(centroid_words), centroid_words)\n",
    "    word_vectors = word_vectors_cache(clean_sentences, emdedding_model)\n",
    "    #Centroid embedding representation\n",
    "    centroid_vector = build_embedding_representation(centroid_words, word_vectors, emdedding_model)\n",
    "    sentences_scores = []\n",
    "    for i in range(len(clean_sentences)):\n",
    "        scores = []\n",
    "        words = clean_sentences[i].split()\n",
    "\n",
    "        #Sentence embedding representation\n",
    "        sentence_vector = build_embedding_representation(words, word_vectors, emdedding_model)\n",
    "\n",
    "        #Cosine similarity between sentence embedding and centroid embedding\n",
    "        score = similarity(sentence_vector, centroid_vector)\n",
    "        sentences_scores.append((i, raw_sentences[i], score, sentence_vector))\n",
    "    sentence_scores_sort = sorted(sentences_scores, key=lambda el: el[2], reverse=True)\n",
    "    for s in sentence_scores_sort:\n",
    "        print(s[0], s[1], s[2])\n",
    "    count = 0\n",
    "    sentences_summary = []\n",
    "    #Handle redundancy\n",
    "    for s in sentence_scores_sort:\n",
    "        if count > 100:\n",
    "            break\n",
    "        include_flag = True\n",
    "        for ps in sentences_summary:\n",
    "            sim = similarity(s[3], ps[3])\n",
    "            if sim > 0.95:\n",
    "                include_flag = False\n",
    "        if include_flag:\n",
    "            sentences_summary.append(s)\n",
    "            count += len(s[1].split())\n",
    "\n",
    "        sentences_summary = sorted(sentences_summary, key=lambda el: el[0], reverse=False)\n",
    "\n",
    "    summary = \"\\n\".join([s[1] for s in sentences_summary])\n",
    "    print(summary)\n",
    "    return summary\n",
    "\n",
    "text = \"\"\"In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub\n",
    "          which has been launched to empower the next generation of students with AI-ready skills.\n",
    "         Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100\n",
    "          institutions with AI infrastructure, course content and curriculum, developer support,\n",
    "          development tools and give students access to cloud and AI services.\n",
    "          As part of the program, the Redmond giant which wants to expand its reach and is\n",
    "          planning to build a strong developer ecosystem in India with the program will set up the\n",
    "          core AI infrastructure and IoT Hub for the selected campuses.\n",
    "          The company will provide AI development tools and Azure AI services such as\n",
    "          Microsoft Cognitive Services, Bot Services and Azure Machine Learning.\n",
    "          According to Manish Prakash, Country General Manager-PS, Health and Education,\n",
    "          Microsoft India, said, \"With AI being the defining technology of our time,\n",
    "          it is transforming lives and industry and the jobs of tomorrow will\n",
    "          require a different skillset. This will require more collaborations and\n",
    "          training and working with AI. That’s why it has become more critical than ever for\n",
    "          educational institutions to integrate new cloud and AI technologies.\n",
    "          The program is an attempt to ramp up the institutional set-up and build\n",
    "          capabilities among the educators to educate the workforce of tomorrow.\"\n",
    "          The program aims to build up the cognitive skills and in-depth understanding of\n",
    "          developing intelligent cloud connected solutions for applications across industry.\n",
    "          Earlier in April this year, the company announced Microsoft Professional\n",
    "          Program In AI as a learning track open to the public.\n",
    "          The program was developed to provide job ready skills to programmers who wanted to hone their\n",
    "          skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well.\n",
    "          This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.\"\"\"\n",
    "\n",
    "clean_sentences = cleanup_sentences(text)\n",
    "words = []\n",
    "for sent in clean_sentences:\n",
    "    words.append(nlkt_word_tokenize(sent))\n",
    "model = Word2Vec(words, min_count=1, sg = 1)\n",
    "summarize(text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822dd4c6",
   "metadata": {},
   "source": [
    "#pip install aspect-based-sentiment-analysis --user\n",
    "import aspect_based_sentiment_analysis as absa\n",
    "\n",
    "absa_nlp = absa.load()\n",
    "text = (\"We are great fans of Slack, but we wish the subscriptions \"\n",
    "        \"were more accessible to small startups.\")\n",
    "\n",
    "slack, price = absa_nlp(text, aspects=['slack', 'price'])\n",
    "assert price.sentiment == absa.Sentiment.negative\n",
    "assert slack.sentiment == absa.Sentiment.positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa30f7-60d7-496e-b8f3-7d96a6e006d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contraction_list = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e4ae6e-6726-4299-a81c-3d29225397c6",
   "metadata": {},
   "source": [
    "## Other options\n",
    "* lemmatization: https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "* tonkenizer: https://neptune.ai/blog/tokenization-in-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811a8b1-ffcf-4854-9c0b-c1bfca50ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk.corpus\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('punkt') # for the tokenizer\n",
    "#nltk.download('averaged_perceptron_tagger') # for POS\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "def clean_text(text, normalize = True, contraction_list = contraction_list, remove_stopwords = True, stop_words = stop_words, \n",
    "               tokenizer = nltk.word_tokenize, lemmatizer = WordNetLemmatizer(), pos_tag = nltk.pos_tag):\n",
    "    '''Return tokenized text, with the options:\n",
    "    Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings\n",
    "    '''\n",
    "    \n",
    "    if normalize: # Convert words to lower case\n",
    "        text = text.lower()\n",
    "    \n",
    "    # Removing mentions (@person), \n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|^rt\", \"\", text)\n",
    "    # Tabs\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # Links\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    # Extra space\n",
    "    # text = re.sub('\\s+',' ',text)\n",
    "    # HTML\n",
    "    #text = re.sub(r'(\\<a href)|(<br />)', '', text)\n",
    "    #text = re.sub(r'&amp;', '', text) \n",
    "    #text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    # Numbers\n",
    "    #text = re.sub(r\"[0-9]\", \"\",text)\n",
    "    # Hashtags\n",
    "    #text = re.sub(r\"#\\S+\", \"\",text)\n",
    "    \n",
    "    if contraction_list:\n",
    "        text = re.findall(r\"[\\w']+\", text)\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contraction_list:\n",
    "                new_text.append(contraction_list[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = \" \".join([word for word in text.split() if word not in (stop_words)])\n",
    "    \n",
    "    # Tokenizer\n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    if lemmatizer: # Lemmatization\n",
    "        #text = \" \".join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "        text = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    if pos_tag:\n",
    "        pos = pos_tag(tokens)\n",
    "        \n",
    "    return text, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e10956-da8c-4570-a7d6-8e7b6bddb21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These bars are delicious not to mention gluten free. Eating gluten free does not often leave many easy to grab breakfast foods. These bars are tasty, all natural and easy.\n",
      "['bar', 'delicious', 'mention', 'gluten', 'free', 'eating', 'gluten', 'free', 'often', 'leave', 'many', 'easy', 'grab', 'breakfast', 'food', 'bar', 'tasty', 'natural', 'easy']\n",
      "[('bars', 'NNS'), ('delicious', 'JJ'), ('mention', 'NN'), ('gluten', 'NNS'), ('free', 'JJ'), ('eating', 'VBG'), ('gluten', 'JJ'), ('free', 'JJ'), ('often', 'RB'), ('leave', 'VBP'), ('many', 'JJ'), ('easy', 'JJ'), ('grab', 'NN'), ('breakfast', 'NN'), ('foods', 'NNS'), ('bars', 'NNS'), ('tasty', 'JJ'), ('natural', 'JJ'), ('easy', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "text = product_df['reviewText'].iloc[0]\n",
    "print(text)\n",
    "text, pos = clean_text(text)\n",
    "print(text)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e01a34-1448-46dd-92dd-3a464f1201c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'bar': 2, 'gluten': 2, 'free': 2, 'easy': 2, 'delicious': 1, 'mention': 1, 'eating': 1, 'often': 1, 'leave': 1, 'many': 1, 'grab': 1, 'breakfast': 1, 'food': 1, 'tasty': 1, 'natural': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10192585-0587-41b1-b543-380a7fde0c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"05840d1b51e04ff8a9c9911441c1c793-0\" class=\"displacy\" width=\"1700\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">tea</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">very</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">nice,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">best</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">part</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1480\">extremely</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1480\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">cheap</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,167.0 145.0,167.0 145.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-4\" stroke-width=\"2px\" d=\"M290,222.0 C290,57.0 595.0,57.0 595.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595.0,224.0 L603.0,212.0 587.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,112.0 920.0,112.0 920.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-6\" stroke-width=\"2px\" d=\"M840,222.0 C840,167.0 915.0,167.0 915.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,224.0 L832,212.0 848,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-7\" stroke-width=\"2px\" d=\"M950,222.0 C950,167.0 1025.0,167.0 1025.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950,224.0 L942,212.0 958,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-8\" stroke-width=\"2px\" d=\"M290,222.0 C290,2.0 1040.0,2.0 1040.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1040.0,224.0 L1048.0,212.0 1032.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,112.0 1360.0,112.0 1360.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-10\" stroke-width=\"2px\" d=\"M1280,222.0 C1280,167.0 1355.0,167.0 1355.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1280,224.0 L1272,212.0 1288,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-11\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,57.0 1365.0,57.0 1365.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1365.0,224.0 L1373.0,212.0 1357.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-12\" stroke-width=\"2px\" d=\"M1500,222.0 C1500,167.0 1575.0,167.0 1575.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1500,224.0 L1492,212.0 1508,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-05840d1b51e04ff8a9c9911441c1c793-0-13\" stroke-width=\"2px\" d=\"M1390,222.0 C1390,112.0 1580.0,112.0 1580.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-05840d1b51e04ff8a9c9911441c1c793-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1580.0,224.0 L1588.0,212.0 1572.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "#doc = nlp(\" \".join(text))\n",
    "#doc = nlp(product_df['reviewText'].iloc[0])\n",
    "doc = nlp(\"The tea is very nice, and the best part is that it is extremely cheap\")\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})#, 'compact': 'True'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f7df4-d736-4f13-976b-032317653c9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4013080679.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [17]\u001b[1;36m\u001b[0m\n\u001b[1;33m    if token.dep_:<{22}\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    if token.dep_:<{22} \n",
    "    print(f'{token.text:{12}} {token.head} {token.dep_:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feadb0f8-cf0d-4284-8a21-b2d4ff189b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\displacy\\__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">These bars are delicious not to mention gluten free. Eating gluten free does not often leave many easy to grab breakfast foods. These bars are tasty, all natural and easy.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809ea8e-0b9d-4a06-9303-63ef2ed14255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.538, 'pos': 0.462, 'compound': 0.9568}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "review = product_df['reviewText'].iloc[0]\n",
    "# Obtain the sid scores for your review\n",
    "sid.polarity_scores(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b275e-fe5c-4ea6-8530-180924d7d120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667275</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>06 26, 2009</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>These bars are delicious not to mention gluten...</td>\n",
       "      <td>KIND Plus Cranberry &amp; Almond, 1.4 Ounce Bars (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667276</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>07 9, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>Yummy.... great if you like nuts</td>\n",
       "      <td>Yummy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667277</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 9, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>Very good! Be kind to yourself, try one! Good ...</td>\n",
       "      <td>I am super picky and these are very good!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667278</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 9, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>Yum</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667279</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 9, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>good price, taste great! the nutrients (protei...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095310</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 10, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>KIND bars are always so yummy!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095311</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 10, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>LOVE these Be Kind bars but this past delivery...</td>\n",
       "      <td>How the vendor stores this product matters to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095312</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 10, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>TASTES GOOD.</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095313</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 10, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>So good! But don't be fooled when it says \"les...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095314</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 9, 2018</td>\n",
       "      <td>B00BUKL666</td>\n",
       "      <td>Very good always being these.</td>\n",
       "      <td>Tasty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7383 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         overall  verified   reviewTime        asin  \\\n",
       "667275       5.0     False  06 26, 2009  B00BUKL666   \n",
       "667276       5.0     False   07 9, 2018  B00BUKL666   \n",
       "667277       5.0      True   07 9, 2018  B00BUKL666   \n",
       "667278       5.0      True   07 9, 2018  B00BUKL666   \n",
       "667279       5.0      True   07 9, 2018  B00BUKL666   \n",
       "...          ...       ...          ...         ...   \n",
       "1095310      5.0      True  07 10, 2018  B00BUKL666   \n",
       "1095311      3.0      True  07 10, 2018  B00BUKL666   \n",
       "1095312      4.0      True  07 10, 2018  B00BUKL666   \n",
       "1095313      5.0      True  07 10, 2018  B00BUKL666   \n",
       "1095314      5.0      True   07 9, 2018  B00BUKL666   \n",
       "\n",
       "                                                reviewText  \\\n",
       "667275   These bars are delicious not to mention gluten...   \n",
       "667276                    Yummy.... great if you like nuts   \n",
       "667277   Very good! Be kind to yourself, try one! Good ...   \n",
       "667278                                                 Yum   \n",
       "667279   good price, taste great! the nutrients (protei...   \n",
       "...                                                    ...   \n",
       "1095310                     KIND bars are always so yummy!   \n",
       "1095311  LOVE these Be Kind bars but this past delivery...   \n",
       "1095312                                       TASTES GOOD.   \n",
       "1095313  So good! But don't be fooled when it says \"les...   \n",
       "1095314                      Very good always being these.   \n",
       "\n",
       "                                                   summary vote style  \n",
       "667275   KIND Plus Cranberry & Almond, 1.4 Ounce Bars (...  NaN   NaN  \n",
       "667276                                               Yummy  NaN   NaN  \n",
       "667277           I am super picky and these are very good!  NaN   NaN  \n",
       "667278                                          Five Stars  NaN   NaN  \n",
       "667279                                          Five Stars  NaN   NaN  \n",
       "...                                                    ...  ...   ...  \n",
       "1095310                                         Five Stars  NaN   NaN  \n",
       "1095311  How the vendor stores this product matters to ...  NaN   NaN  \n",
       "1095312                                         Four Stars  NaN   NaN  \n",
       "1095313                                         Five Stars  NaN   NaN  \n",
       "1095314                                              Tasty  NaN   NaN  \n",
       "\n",
       "[7383 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f6ac2-d3cb-480d-818e-06034e75c62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These        bars det                    these\n",
      "bars         are nsubj                  bar\n",
      "are          are ROOT                   be\n",
      "delicious    are acomp                  delicious\n",
      "not          mention neg                    not\n",
      "to           mention aux                    to\n",
      "mention      delicious xcomp                  mention\n",
      "gluten       free amod                   gluten\n",
      "free         mention ccomp                  free\n",
      ".            are punct                  .\n",
      "Eating       leave csubj                  eat\n",
      "gluten       free amod                   gluten\n",
      "free         Eating advmod                 free\n",
      "does         leave aux                    do\n",
      "not          leave neg                    not\n",
      "often        leave advmod                 often\n",
      "leave        leave ROOT                   leave\n",
      "many         easy amod                   many\n",
      "easy         leave dobj                   easy\n",
      "to           grab aux                    to\n",
      "grab         leave xcomp                  grab\n",
      "breakfast    foods compound               breakfast\n",
      "foods        grab dobj                   food\n",
      ".            leave punct                  .\n",
      "These        bars det                    these\n",
      "bars         are nsubj                  bar\n",
      "are          are ROOT                   be\n",
      "tasty        are acomp                  tasty\n",
      ",            are punct                  ,\n",
      "all          natural advmod                 all\n",
      "natural      are acomp                  natural\n",
      "and          natural cc                     and\n",
      "easy         natural conj                   easy\n",
      ".            are punct                  .\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "text = doc\n",
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.head} {token.dep_:<{22}} {token.lemma_}')\n",
    "        \n",
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ae8c2-6eff-4c24-a48c-c6471bb699e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>attributes</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [original, attributes, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(columns=['original','lemma','attributes','sentiment']).set_index('lemma')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273db82-f0c3-473e-aff9-0eca91863b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "These bars are delicious not to mention gluten free. Eating gluten free does not often leave many easy to grab breakfast foods. These bars are tasty, all natural and easy."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97fd17-3a44-4788-a097-9e62beaf477f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"eba3fb61c3bb4720bdaae6233f583158-0\" class=\"displacy\" width=\"3350\" height=\"412.0\" direction=\"ltr\" style=\"max-width: none; height: 412.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">These</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">bars</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">delicious</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">mention</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">gluten</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">free.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">Eating</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">gluten</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">free</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">does</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1480\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1480\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">often</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\">leave</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1810\">many</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1810\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1920\">easy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1920\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2030\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2030\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2140\">grab</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2140\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2250\">breakfast</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2360\">foods.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2360\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2470\">These</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2470\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2580\">bars</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2580\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2690\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2690\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2800\">tasty,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2800\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2910\">all</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2910\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3020\">natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3020\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3130\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3130\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"322.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3240\">easy.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3240\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-0\" stroke-width=\"2px\" d=\"M70,277.0 C70,222.0 140.0,222.0 140.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,279.0 L62,267.0 78,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-1\" stroke-width=\"2px\" d=\"M180,277.0 C180,222.0 250.0,222.0 250.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,279.0 L172,267.0 188,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-2\" stroke-width=\"2px\" d=\"M290,277.0 C290,222.0 360.0,222.0 360.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M360.0,279.0 L368.0,267.0 352.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-3\" stroke-width=\"2px\" d=\"M510,277.0 C510,167.0 695.0,167.0 695.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M510,279.0 L502,267.0 518,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-4\" stroke-width=\"2px\" d=\"M620,277.0 C620,222.0 690.0,222.0 690.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M620,279.0 L612,267.0 628,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-5\" stroke-width=\"2px\" d=\"M400,277.0 C400,112.0 700.0,112.0 700.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700.0,279.0 L708.0,267.0 692.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-6\" stroke-width=\"2px\" d=\"M840,277.0 C840,222.0 910.0,222.0 910.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,279.0 L832,267.0 848,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-7\" stroke-width=\"2px\" d=\"M730,277.0 C730,167.0 915.0,167.0 915.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,279.0 L923.0,267.0 907.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-8\" stroke-width=\"2px\" d=\"M1060,277.0 C1060,2.0 1700.0,2.0 1700.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">csubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,279.0 L1052,267.0 1068,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-9\" stroke-width=\"2px\" d=\"M1170,277.0 C1170,222.0 1240.0,222.0 1240.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,279.0 L1162,267.0 1178,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-10\" stroke-width=\"2px\" d=\"M1060,277.0 C1060,167.0 1245.0,167.0 1245.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1245.0,279.0 L1253.0,267.0 1237.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-11\" stroke-width=\"2px\" d=\"M1390,277.0 C1390,112.0 1690.0,112.0 1690.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1390,279.0 L1382,267.0 1398,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-12\" stroke-width=\"2px\" d=\"M1500,277.0 C1500,167.0 1685.0,167.0 1685.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1500,279.0 L1492,267.0 1508,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-13\" stroke-width=\"2px\" d=\"M1610,277.0 C1610,222.0 1680.0,222.0 1680.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610,279.0 L1602,267.0 1618,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-14\" stroke-width=\"2px\" d=\"M1830,277.0 C1830,222.0 1900.0,222.0 1900.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1830,279.0 L1822,267.0 1838,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-15\" stroke-width=\"2px\" d=\"M1720,277.0 C1720,167.0 1905.0,167.0 1905.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1905.0,279.0 L1913.0,267.0 1897.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-16\" stroke-width=\"2px\" d=\"M2050,277.0 C2050,222.0 2120.0,222.0 2120.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2050,279.0 L2042,267.0 2058,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-17\" stroke-width=\"2px\" d=\"M1720,277.0 C1720,57.0 2135.0,57.0 2135.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2135.0,279.0 L2143.0,267.0 2127.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-18\" stroke-width=\"2px\" d=\"M2270,277.0 C2270,222.0 2340.0,222.0 2340.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2270,279.0 L2262,267.0 2278,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-19\" stroke-width=\"2px\" d=\"M2160,277.0 C2160,167.0 2345.0,167.0 2345.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345.0,279.0 L2353.0,267.0 2337.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-20\" stroke-width=\"2px\" d=\"M2490,277.0 C2490,222.0 2560.0,222.0 2560.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2490,279.0 L2482,267.0 2498,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-21\" stroke-width=\"2px\" d=\"M2600,277.0 C2600,222.0 2670.0,222.0 2670.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2600,279.0 L2592,267.0 2608,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-22\" stroke-width=\"2px\" d=\"M2710,277.0 C2710,222.0 2780.0,222.0 2780.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2780.0,279.0 L2788.0,267.0 2772.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-23\" stroke-width=\"2px\" d=\"M2930,277.0 C2930,222.0 3000.0,222.0 3000.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2930,279.0 L2922,267.0 2938,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-24\" stroke-width=\"2px\" d=\"M2710,277.0 C2710,112.0 3010.0,112.0 3010.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3010.0,279.0 L3018.0,267.0 3002.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-25\" stroke-width=\"2px\" d=\"M3040,277.0 C3040,222.0 3110.0,222.0 3110.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3110.0,279.0 L3118.0,267.0 3102.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eba3fb61c3bb4720bdaae6233f583158-0-26\" stroke-width=\"2px\" d=\"M3040,277.0 C3040,167.0 3225.0,167.0 3225.0,277.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eba3fb61c3bb4720bdaae6233f583158-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3225.0,279.0 L3233.0,267.0 3217.0,267.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})#, 'compact': 'True'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef74cb-c0f2-4647-b5bd-f27c09e66d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         dataframe\u001b[38;5;241m.\u001b[39mloc[token\u001b[38;5;241m.\u001b[39mlemma_,:] \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mtext, token\u001b[38;5;241m.\u001b[39mdep_, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mdep_ \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macomp\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m---> 10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdep_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     11\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m dataframe\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "#dataframe = pd.DataFrame(columns=['lemma']) #,'category','sentiment'\n",
    "doc = nlp(product_df['reviewText'].iloc[0])\n",
    "\n",
    "i = 0\n",
    "for token in doc:\n",
    "    if token.dep_ == 'nsubj':\n",
    "        dataframe.loc[token.lemma_,:] = [token.text, token.dep_, 0]\n",
    "    if token.dep_ in {'acomp'}:\n",
    "        found = False\n",
    "        while not found:\n",
    "            if\n",
    "        print(token.dep_[i])\n",
    "    i += 1\n",
    "            \n",
    "            \n",
    "        \n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc99445-50f6-4565-8f4b-0084bcc2e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The product itself is good however this company has a terrible service.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf0132-2489-4e25-a8e1-7c15e80218dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = self.parser.parseToStanfordDependencies(\"Pick up the tire pallet.\")\n",
    "       tupleResult = [(rel, gov.text, dep.text) for rel, gov, dep in dependencies.dependencies]\n",
    "       self.assertEqual(tupleResult, [('prt', 'Pick', 'up'),\n",
    "                                      ('det', 'pallet', 'the'),\n",
    "                                      ('nn', 'pallet', 'tire'),\n",
    "                                      ('dobj', 'Pick', 'pallet')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2840a-ba40-40ac-af18-84112d7b3b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>attributes</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bars</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original attributes sentiment lemma\n",
       "0     bars      nsubj         0   NaN\n",
       "1      NaN        NaN       NaN     ."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.concat([dataframe,pd.DataFrame({'lemma':token.lemma_}, index=[dataframe.shape[0]])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416bfa54-7529-4d0b-8920-c6013e34e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the word to the set of stop words. Use lowercase!\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['btw'].is_stop = True\n",
    "\n",
    "# Remove the word from the set of stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "# Remove the stop_word tag from the lexeme\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7088537-fa64-433a-bb92-1a71ab4f2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be18585-3a23-4e04-8a5f-3ede1dc29478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('These', 'DT'),\n",
       " ('bars', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('delicious', 'JJ'),\n",
       " ('not', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('mention', 'VB'),\n",
       " ('gluten', 'JJ'),\n",
       " ('free', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Eating', 'VBG'),\n",
       " ('gluten', 'JJ'),\n",
       " ('free', 'JJ'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('often', 'RB'),\n",
       " ('leave', 'VBP'),\n",
       " ('many', 'JJ'),\n",
       " ('easy', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('grab', 'VB'),\n",
       " ('breakfast', 'NN'),\n",
       " ('foods', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('These', 'DT'),\n",
       " ('bars', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('tasty', 'JJ'),\n",
       " (',', ','),\n",
       " ('all', 'DT'),\n",
       " ('natural', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('easy', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = product_df['reviewText'].iloc[0]\n",
    "# Tokenize\n",
    "text = nltk.tokenize.word_tokenize(text, language='english', preserve_line=False)\n",
    "# Tag\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d82dc-6f80-49ca-b161-715c80393f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bash\n",
    "ipython nbconvert --to latex --template citations.tplx QuadraticEquations.ipynb\n",
    "pdflatex QuadraticEquations.tex\n",
    "bibtex QuadraticEquations\n",
    "pdflatex QuadraticEquations.tex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "52ad0f2a9a61e918364436633dcfa36c2df401545a7e044092ecd096fbb570fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
